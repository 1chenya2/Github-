import streamlit as st
import numpy as np
import pandas as pd
from PIL import Image
import joblib

# åŠ è½½æ¨¡å‹
model_path = "stacking_regressor_model.pkl"
stacking_regressor = joblib.load(model_path)

# è®¾ç½®é¡µé¢é…ç½®å’Œæ ‡é¢˜
st.set_page_config(layout="wide", page_title="Stacking æ¨¡å‹é¢„æµ‹ä¸ SHAP å¯è§†åŒ–", page_icon="ğŸ“Š")

st.title("ğŸ“Š Stacking æ¨¡å‹é¢„æµ‹ä¸ SHAP å¯è§†åŒ–åˆ†æ")
st.write("""
é€šè¿‡è¾“å…¥ç‰¹å¾å€¼è¿›è¡Œæ¨¡å‹é¢„æµ‹ï¼Œå¹¶ç»“åˆ SHAP åˆ†æç»“æœï¼Œäº†è§£ç‰¹å¾å¯¹æ¨¡å‹é¢„æµ‹çš„è´¡çŒ®ã€‚
""")

# å·¦ä¾§ä¾§è¾¹æ è¾“å…¥åŒºåŸŸ
st.sidebar.header("ç‰¹å¾è¾“å…¥åŒºåŸŸ")
st.sidebar.write("è¯·è¾“å…¥ç‰¹å¾å€¼ï¼š")

# å®šä¹‰ç‰¹å¾è¾“å…¥èŒƒå›´
depression = st.sidebar.number_input("ç‰¹å¾ depression  (èŒƒå›´: 0-1)", min_value=0, max_value=1, value=1)
wavelet_HHL_glrlm_RunLengthNonUniformityNormalized = st.sidebar.number_input("ç‰¹å¾ wavelet.HHL.glrlm.RunLengthNonUniformityNormalized  (èŒƒå›´: 0.338031-0.4071359)", min_value=0.338031, max_value=0.4071359, value=0.392841974686494)
wavelet_HHL_firstorder_Median = st.sidebar.number_input("ç‰¹å¾ wavelet.HHL.firstorder.Median  (èŒƒå›´: -0.015689-0.1198817)", min_value=-0.015689, max_value=0.1198817, value=0.052452842888068)
wavelet_HHL_glszm_ZonePercentage = st.sidebar.number_input("ç‰¹å¾ wavelet.HHL.glszm.ZonePercentage (èŒƒå›´: 0.003914-0.03386989)", min_value=0.003914, max_value=0.03386989, value=0.0144873000940733)
wavelet_HLH_glcm_MCC = st.sidebar.number_input("ç‰¹å¾ wavelet.HLH.glcm.MCC (èŒƒå›´: 0.309678-0.7596631)", min_value=0.309678, max_value=0.7596631, value=0.634320591738265)
original_glrlm_GrayLevelNonUniformity = st.sidebar.number_input("ç‰¹å¾ original.glrlm.GrayLevelNonUniformity (èŒƒå›´: 1266.161072-4581.778)", min_value=1266.161072, max_value=4581.778, value=2156.59078743461)
wavelet_LLL_glcm_ClusterProminence = st.sidebar.number_input("ç‰¹å¾ wavelet.LLL.glcm.ClusterProminence (èŒƒå›´: 1316.540948-144454.3)", min_value=1316.540948, max_value=144454.3, value=5461.81471258063)
wavelet_HLH_glszm_LargeAreaHighGrayLevelEmphasis = st.sidebar.number_input("ç‰¹å¾ wavelet.HLH.glszm.LargeAreaHighGrayLevelEmphasis (èŒƒå›´: 178720.643290åˆ°10806650.0)", min_value=178720.643290, max_value=10806650.0, value=932798.531407035)
wavelet_HLH_gldm_LargeDependenceHighGrayLevelEmphasis = st.sidebar.number_input("ç‰¹å¾ wavelet.HLH.gldm.LargeDependenceHighGrayLevelEmphasis  (èŒƒå›´: 431.904614-5722.353)", min_value=431.904614, max_value=5722.353, value=1328.63372530573)
original_shape_VoxelVolume = st.sidebar.number_input("ç‰¹å¾ original.shape.VoxelVolume  (èŒƒå›´: 11102.428979-96702.95)", min_value=11102.428979, max_value=96702.95, value=49674.0341186523)
original_glcm_Autocorrelation = st.sidebar.number_input("ç‰¹å¾ original.glcm.Autocorrelation  (èŒƒå›´: 9.951094-57.70954)", min_value=9.951094, max_value=57.70954, value=13.4272036676023)
wavelet_LLH_glcm_MCC = st.sidebar.number_input("ç‰¹å¾ wavelet.LLH.glcm.MCC   (èŒƒå›´: 0.775903-0.9841110)", min_value=0.775903, max_value=0.9841110, value=0.906120059179769)
ALB = st.sidebar.number_input("ç‰¹å¾ ALB  (èŒƒå›´: 30.400000-50.30000)", min_value=30.400000, max_value=50.30000, value=36.5)
Operative_time = st.sidebar.number_input("ç‰¹å¾ Operative.time   (èŒƒå›´: 49-550)", min_value=49, max_value=550, value=550)
# æ·»åŠ é¢„æµ‹æŒ‰é’®
predict_button = st.sidebar.button("è¿›è¡Œé¢„æµ‹")

# ä¸»é¡µé¢ç”¨äºç»“æœå±•ç¤º
if predict_button:
    st.header("é¢„æµ‹ç»“æœ")
    try:
        # å°†è¾“å…¥ç‰¹å¾è½¬æ¢ä¸ºæ¨¡å‹æ‰€éœ€æ ¼å¼
        input_array = np.array([depression, wavelet_HHL_glrlm_RunLengthNonUniformityNormalized, wavelet_HHL_firstorder_Median, wavelet_HHL_glszm_ZonePercentage, wavelet_HLH_glcm_MCC, original_glrlm_GrayLevelNonUniformity,wavelet_LLL_glcm_ClusterProminence, wavelet_HLH_glszm_LargeAreaHighGrayLevelEmphasis,wavelet_HLH_gldm_LargeDependenceHighGrayLevelEmphasis,original_shape_VoxelVolume,original_glcm_Autocorrelation,wavelet_LLH_glcm_MCC,ALB,Operative_time]).reshape(1, -1)

        # æ¨¡å‹é¢„æµ‹
        prediction = stacking_regressor.predict(input_array)[0]

        # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
        st.success(f"é¢„æµ‹ç»“æœï¼š{prediction:.2f}")
    except Exception as e:
        st.error(f"é¢„æµ‹æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

# å¯è§†åŒ–å±•ç¤º
st.header("SHAP å¯è§†åŒ–åˆ†æ")
st.write("""
ä»¥ä¸‹å›¾è¡¨å±•ç¤ºäº†æ¨¡å‹çš„ SHAP åˆ†æç»“æœï¼ŒåŒ…æ‹¬ç¬¬ä¸€å±‚åŸºå­¦ä¹ å™¨ã€ç¬¬äºŒå±‚å…ƒå­¦ä¹ å™¨ä»¥åŠæ•´ä¸ª Stacking æ¨¡å‹çš„ç‰¹å¾è´¡çŒ®ã€‚
""")

# ç¬¬ä¸€å±‚åŸºå­¦ä¹ å™¨ SHAP å¯è§†åŒ–
st.subheader("1. ç¬¬ä¸€å±‚åŸºå­¦ä¹ å™¨")
st.write("åŸºå­¦ä¹ å™¨ï¼ˆRandomForestã€XGBã€LGBM ç­‰ï¼‰çš„ç‰¹å¾è´¡çŒ®åˆ†æã€‚")
first_layer_img = "summary_plot.png"
try:
    img1 = Image.open(first_layer_img)
    st.image(img1, caption="ç¬¬ä¸€å±‚åŸºå­¦ä¹ å™¨çš„ SHAP è´¡çŒ®åˆ†æ", use_column_width=True)
except FileNotFoundError:
    st.warning("æœªæ‰¾åˆ°ç¬¬ä¸€å±‚åŸºå­¦ä¹ å™¨çš„ SHAP å›¾åƒæ–‡ä»¶ã€‚")

# ç¬¬äºŒå±‚å…ƒå­¦ä¹ å™¨ SHAP å¯è§†åŒ–
st.subheader("2. ç¬¬äºŒå±‚å…ƒå­¦ä¹ å™¨")
st.write("å…ƒå­¦ä¹ å™¨ï¼ˆLinear Regressionï¼‰çš„è¾“å…¥ç‰¹å¾è´¡çŒ®åˆ†æã€‚")
meta_layer_img = "SHAP Contribution Analysis for the Meta-Learner in the Second Layer of Stacking Regressor.png"
try:
    img2 = Image.open(meta_layer_img)
    st.image(img2, caption="ç¬¬äºŒå±‚å…ƒå­¦ä¹ å™¨çš„ SHAP è´¡çŒ®åˆ†æ", use_column_width=True)
except FileNotFoundError:
    st.warning("æœªæ‰¾åˆ°ç¬¬äºŒå±‚å…ƒå­¦ä¹ å™¨çš„ SHAP å›¾åƒæ–‡ä»¶ã€‚")

# æ•´ä½“ Stacking æ¨¡å‹ SHAP å¯è§†åŒ–
st.subheader("3. æ•´ä½“ Stacking æ¨¡å‹")
st.write("æ•´ä¸ª Stacking æ¨¡å‹çš„ç‰¹å¾è´¡çŒ®åˆ†æã€‚")
overall_img = "Based on the overall feature contribution analysis of SHAP to the stacking model.png"
try:
    img3 = Image.open(overall_img)
    st.image(img3, caption="æ•´ä½“ Stacking æ¨¡å‹çš„ SHAP è´¡çŒ®åˆ†æ", use_column_width=True)
except FileNotFoundError:
    st.warning("æœªæ‰¾åˆ°æ•´ä½“ Stacking æ¨¡å‹çš„ SHAP å›¾åƒæ–‡ä»¶ã€‚")

# é¡µè„š
st.markdown("---")
st.header("æ€»ç»“")
st.write("""
é€šè¿‡æœ¬é¡µé¢ï¼Œæ‚¨å¯ä»¥ï¼š
1. ä½¿ç”¨è¾“å…¥ç‰¹å¾å€¼è¿›è¡Œå®æ—¶é¢„æµ‹ã€‚
2. ç›´è§‚åœ°ç†è§£ç¬¬ä¸€å±‚åŸºå­¦ä¹ å™¨ã€ç¬¬äºŒå±‚å…ƒå­¦ä¹ å™¨ä»¥åŠæ•´ä½“ Stacking æ¨¡å‹çš„ç‰¹å¾è´¡çŒ®æƒ…å†µã€‚
è¿™äº›åˆ†ææœ‰åŠ©äºæ·±å…¥ç†è§£æ¨¡å‹çš„é¢„æµ‹é€»è¾‘å’Œç‰¹å¾çš„é‡è¦æ€§ã€‚
""")
